{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible = pd.read_csv('corpus/credible.csv', header=None, names=['id', 'type', 'domain', 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible = credible[(credible['domain'] != 'www.msn.com') & (credible['domain'] != 'feed.reuters.com')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "others = credible[~credible['domain'].isin(['nytimes.com', 'nationalreview.com', 'www.reuters.com', 'weeklystandard.com'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "nlp = spacy.load('en')\n",
    "nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cleaner(dict):\n",
    "    \"\"\" Multiple-string-substitution dict \"\"\"\n",
    "    def _make_regex(self):\n",
    "        \"\"\" Build re object based on the keys of the dictionary it is instantiated with\"\"\"\n",
    "        return re.compile(\"|\".join(map(re.escape, self.keys(  ))))\n",
    "\n",
    "    def __call__(self, match):\n",
    "        \"\"\" Handler invoked for each regex match \"\"\"\n",
    "        return self[match.group(0)]\n",
    "\n",
    "    def clean(self, text):\n",
    "        \"\"\" Substitutes with value for each key and returns the modified text. \"\"\"\n",
    "        return self._make_regex(  ).sub(self, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replacements = {#\"\\n\": \" \", # new line characters\n",
    "                \"\\t\": \" \", # tabs\n",
    "                \"-\": \" \",\n",
    "                \"won't\": \"will not\",\n",
    "                \"can't\": \"can not\",\n",
    "                \"&\": \" and \",\n",
    "                \"$$\": \"$\",\n",
    "                \"Loading...\": \" \",\n",
    "                \"Continued...\": \" \",\n",
    "                \"\\N{COPYRIGHT SIGN}\": \" \",\n",
    "                \"\\N{NO-BREAK SPACE}\": \" \",\n",
    "                \"\\N{LEFT-POINTING DOUBLE ANGLE QUOTATION MARK}\": \" \",\n",
    "                \"\\N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}\": \" \",\n",
    "                '.\"': '\".',\n",
    "                '?\"': '\"?',\n",
    "                '!\"': '\"!',\n",
    "                \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = {'PERSON': 'person',\n",
    "            'FAC': 'landmark',\n",
    "            'ORG': 'organization',\n",
    "            'GPE': 'place',\n",
    "            'LOC': 'location',\n",
    "            'EVENT': 'event',\n",
    "            'WORK_OF_ART': 'artwork',\n",
    "            'LAW': 'law',\n",
    "            'DATE': 'date',\n",
    "            'TIME': 'time',\n",
    "            'PERCENT': 'percent',\n",
    "            'MONEY': 'money',\n",
    "            'QUANTITY': 'quantity',\n",
    "            'CARDINAL': 'number'\n",
    "}\n",
    "\n",
    "ent_order = {'PERSON': 8,\n",
    "            'FAC': 2,\n",
    "            'ORG': 1,\n",
    "            'GPE': 6,\n",
    "            'LOC': 7,\n",
    "            'EVENT': 3,\n",
    "            'WORK_OF_ART': 5,\n",
    "            'LAW': 4,\n",
    "            'DATE': 9,\n",
    "            'TIME': 10,\n",
    "            'PERCENT': 12,\n",
    "            'MONEY': 11,\n",
    "            'QUANTITY': 13,\n",
    "            'CARDINAL': 14,\n",
    "}\n",
    "\n",
    "drop_ents = ['NORP', 'PRODUCT', 'LANGUAGE','ORDINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess = Cleaner(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(in_doc):\n",
    "    count = 0\n",
    "    out_doc = \"\"\n",
    "    doc = re.sub(r'\\n[\\n ]*', ' ', in_doc)\n",
    "    doc = nlp(doc)\n",
    "    if doc._.language['language'] != 'en':\n",
    "        return np.nan\n",
    "    for sent in doc.sents:\n",
    "        ending = sent[-1]\n",
    "        if ending.pos_ != 'PUNCT':\n",
    "            continue\n",
    "        out_doc += (sent.text + ' ')\n",
    "        if ending.text in ['.', '?', '!']:\n",
    "            count += 1\n",
    "    if count < 13:\n",
    "        return count\n",
    "    print(count)\n",
    "    ents = [ent for ent in doc.ents if ent.label_ not in drop_ents]\n",
    "    ents = sorted(ents, key=lambda ent: ent_order[ent.label_])\n",
    "    converted = set([])\n",
    "    for ent in ents:\n",
    "        if (ent.text, ent.label_) in converted:\n",
    "            continue\n",
    "        converted.add((ent.text, ent.label_))\n",
    "        pattern = r'\\b{}\\b'.format(ent.text)\n",
    "        out_doc = re.sub(pattern, entities.get(ent.label_, ent.text), out_doc)\n",
    "    return out_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_quotes(qq):\n",
    "    num = 0\n",
    "    if qq[-2] in ['.', '?', '!']:\n",
    "        punct = qq[-2]\n",
    "    else:\n",
    "        punct = ''\n",
    "    length = len(qq.split())\n",
    "    if length <= 4:\n",
    "        num = 1\n",
    "    elif length <= 12:\n",
    "        num = 2\n",
    "    elif length <= 25:\n",
    "        num = 3\n",
    "    else:\n",
    "        num = 4\n",
    "    return 'quote ' * num + punct\n",
    "\n",
    "def reformat(article):\n",
    "    text = unidecode(article)\n",
    "    if text.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    text = preprocess.clean(text)\n",
    "    text = re.sub(r'^(.{0,50})\\(\\w+\\)', ' ', text) # delete dateline\n",
    "    text = re.sub(r'\\S*@\\S+', 'email', text) # replace email address or Twitter handle with \"email\"\n",
    "    text = re.sub(r'[-a-zA-Z0-9@:%_\\+.~#?&\\/=]{2,256}\\.[a-z]{2,4}(\\/[-a-zA-Z0-9@:%_\\+.~#?&\\/=]*)?', ' website',\n",
    "                  text) # URLs\n",
    "    text = re.sub('[\\[\\(][^\\[\\(]*[\\]\\)]', '', text) # delete text inside parentheses or brackets\n",
    "    text = re.sub(r\"\\b(\\w*)n't\", lambda m: m.group(1) + ' not', text) # replace \"xxn't\" contractions with \"xx not\"; \"won't\" already handled\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text\n",
    "    text = re.sub(r\"^'|'$|(?<= )'|(?<!s)'(?= )\", '\\1\"', text) # replace single quotes, but not apostrophes, with double quotes\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text    \n",
    "    if text.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text\n",
    "    text = re.sub(r'(?i)please share this.*', '', text)\n",
    "    text = re.sub(' +', ' ', text) # reduce all multiple spaces to single spaces\n",
    "    return process(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('corpus/fake.csv', header=None, names=['id', 'type', 'domain', 'content'], dtype={'id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake[fake['domain'] != 'beforeitsnews.com'] .sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = pd.read_csv('corpus/bias.csv', header=None, names=['id', 'type', 'domain', 'content'], dtype={'id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_articles(df):\n",
    "    for ix, row in df.sample(10).iterrows():\n",
    "        yield helper(ix, row)\n",
    "        \n",
    "def helper(ix, row):\n",
    "    print(ix, ', ', row['domain'])\n",
    "    print(reformat(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = show_articles(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-623-737437f873b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fake' is not defined"
     ]
    }
   ],
   "source": [
    "fake['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_contents(df):\n",
    "    for domain in df['domain'].unique():\n",
    "        print(domain)\n",
    "        num = min(len(df[df['domain'] == domain]), 10)\n",
    "        yield df[df['domain'] == domain].sample(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_domains = show_contents(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-620-7524f44b1545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_domains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(bias_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ellen DeGeneres and Celine Dion burning a U.S. flag in front of a …\\n\\nChuck Norris has a reputation as being so tough, it’s legendary. However, it …\\n\\nIn the wake of the horrific mass shooting at a small church in …\\n\\nLess than one week after suspected mass shooter Devin Kelley gunned down at …\\n\\nSometimes even the greatest friendships fail, and duos like Sonny and Cher find …\\n\\nAnother celebrity ego-stroking awards show took place Wednesday night and like all other …\\n\\nA New York church is warning potential shooters not to mess with the …\\n\\nA British man sentenced to life behind bars earlier this year for beating …\\n\\nWith the recent release of recording artist, Taylor Swift’s latest single and video, …\\n\\nIn the wake of any mass shooting, hysteria erupts about guns. All of …\\n\\nAd Blocker Detected\\n\\nOur website is made possible by displaying online advertisements to our visitors. Please consider supporting us by disabling your ad blocker.'"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.loc[1083375, 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_keeper = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_keepers = ['wnd.com', 'frontpagemag.com', 'americanthinker.com', 'dailywire.com', 'thegatewaypundit.com', \n",
    "               'antiwar.com', 'truthrevolt.org', 'patriotpost.us', 'russia-insider.com', 'paulcraigroberts.org',\n",
    "               'vdare.com', 'off-guardian.org', 'jamesrgrangerjr.com', 'americablog.com', 'americasfreedomfighters.com',\n",
    "               'heartland.org', 'palmerreport.com', 'thefederalistpapers.org', 'conservativetribune.com',\n",
    "               'winningdemocrats.com', '100percentfedup.com', 'cowgernation.com', 'usherald.com', 'darkpolitricks.com',\n",
    "               'newslogue.com', 'usapoliticstoday.com', 'counterjihad.com', 'platosguns.com', 'meanlefthook.com',\n",
    "               'americanpatriotdaily.com', 'endingthefed.com', 'conservativefiringline.com', 'politicalcult.com',\n",
    "               'readconservatives.news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformat(bias.loc[543267, 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " | DATE\n",
      "\n",
      "\n",
      "Germany | PERSON\n",
      "Berlin | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "Turkish | NORP\n",
      "Soner Polat | PERSON\n",
      "Sputnik | PERSON\n",
      "Earlier this week | DATE\n",
      "Turkish | NORP\n",
      "Peter Steudtner | PERSON\n",
      "German | NORP\n",
      "six | CARDINAL\n",
      "Amnesty International’s | ORG\n",
      "Turkey | GPE\n",
      "Idil Eser | PERSON\n",
      "Turkish | NORP\n",
      "July 5 | DATE\n",
      "German | NORP\n",
      "Sigmar Gabriel | PERSON\n",
      "Berlin | GPE\n",
      "Ankara | GPE\n",
      "Turkey | GPE\n",
      "Germany | GPE\n",
      "Turkey Spiral | ORG\n",
      "Crisis https://t.co/qDS58JclNa — Janet Orendorff | FAC\n",
      "July 22, 2017 | DATE\n",
      "Turkish | NORP\n",
      "thousands | CARDINAL\n",
      "July 15, 2016 | DATE\n",
      "Islamic | NORP\n",
      "Fethullah Gulen | PERSON\n",
      "Ankara | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "MFA | ORG\n",
      "— Srbija Evropa | PERSON\n",
      "July 20, 2017\n",
      "\n",
      " | DATE\n",
      "Sputnik Turkey | PERSON\n",
      "Retired Rear Admiral | PERSON\n",
      "the Turkish Armed Forces Soner Polat | ORG\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "Turkey | GPE\n",
      "Eurasia | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "1952 | DATE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "Polat | PERSON\n",
      "Turkey | GPE\n",
      "Turkey | GPE\n",
      "July 15 last year | DATE\n",
      "Turkey | GPE\n",
      "Australia | GPE\n",
      "New Zealand | GPE\n",
      "Europe | LOC\n",
      "the United States | GPE\n",
      "the Justice and Development Party | ORG\n",
      "Turkish | NORP\n",
      "Recep Tayyip Erdogan | PERSON\n",
      "Turkey | GPE\n",
      "Erdogan | PERSON\n",
      "Germany | GPE\n",
      "Injirlik | LOC\n",
      "German | NORP\n",
      "Injirlik | LOC\n",
      "Konya | GPE\n",
      "Polat | PERSON\n",
      "Erdogan | PERSON\n",
      "Europe | LOC\n",
      "Netherlands | GPE\n",
      "Germany | GPE\n",
      "British | NORP\n",
      "Boris Johnson | PERSON\n",
      "Brexit | ORG\n",
      "Turkey | GPE\n",
      "Preventing Erdogan | PERSON\n",
      "the G20 summit | EVENT\n",
      "Turkey | GPE\n",
      "West | LOC\n",
      "Polat | LOC\n",
      "Germany | GPE\n",
      "Eurasian | NORP\n",
      "Turkey | GPE\n",
      "Polat | PERSON\n",
      "Berlin | GPE\n",
      "Ankara | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "German | NORP\n",
      "Turkey | GPE\n",
      "Turkey | GPE\n",
      "Greece | GPE\n",
      "Iraq | GPE\n",
      "Syria | GPE\n",
      "late May | DATE\n",
      "Turkish | NORP\n",
      "Mevlut Cavusoglu | PERSON\n",
      "Ankara | GPE\n",
      "German | NORP\n",
      "Incirlik | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "Incirlik’ | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "German | NORP\n",
      "Incirlik | GPE\n",
      "Cavusoglu | ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in nlp(bias.loc[265413, 'content']).ents:\n",
    "    print(ent.text, '|', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Hillary', 'person'), ('NAACP', 'org'), ('Whitman', 'bridge')}"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = set([('Hillary', 'person'), ('NAACP', 'org'), ('Whitman', 'bridge'), ('Hillary', 'person')])\n",
    "tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def silliness(string):\n",
    "    new_string = re.sub(r\"^'|'$|(?<= )'|'(?= )\", '\"', string)\n",
    "    print(new_string.count('\\N{QUOTATION MARK}'))\n",
    "    if new_string.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    return 'WTF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester = nlp('Victims seek to resume Marcos from Heroes\\' Cemetery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tester:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial = 'How about \\u00a9 for a change'\n",
    "print(trial)\n",
    "trial2 = re.sub('\\N{COPYRIGHT SIGN}', 'this', trial)\n",
    "print(trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'How about \\u00a9 for a change'.replace('\\N{COPYRIGHT SIGN}', 'this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "scraper_data = os.listdir('./data')\n",
    "scraped = pd.DataFrame()\n",
    "for file in scraper_data:\n",
    "    try:\n",
    "        df = pd.read_json('./data/{}'.format(file))\n",
    "        scraped = pd.concat([scraped, df])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped = scraped.drop_duplicates(['id'], keep='last')\n",
    "len(scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.drop('id', axis=1).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.drop('domain', axis=1).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1[(df1['type'] != 'unreliable') & (df1['type'] !='unknown')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1[(df1['type'] != 'unreliable') & (df1['type'] !='unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.groupby('type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[df1['type'] == 'political']['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "media_bias = pd.read_csv('data/media_bias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "media_bias[media_bias['Vertical Rank'] >= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_data = pd.read_json('data/abc_20181207.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_data.loc[13, 'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"https://cbsnews.com/world\".count(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
