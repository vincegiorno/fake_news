{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible = pd.read_csv('corpus/credible.csv', header=None, names=['id', 'type', 'domain', 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible = credible[(credible['domain'] != 'www.msn.com') & (credible['domain'] != 'feed.reuters.com')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "others = credible[~credible['domain'].isin(['nytimes.com', 'nationalreview.com', 'www.reuters.com', 'weeklystandard.com'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "nlp = spacy.load('en')\n",
    "#from spacy.pipeline import Sentencizer\n",
    "\n",
    "#sentencizer = Sentencizer(['.', '?', '!', '\\n'])\n",
    "nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cleaner(dict):\n",
    "    \"\"\" Multiple-string-substitution dict \"\"\"\n",
    "    def _make_regex(self):\n",
    "        \"\"\" Build re object based on the keys of the dictionary it is instantiated with\"\"\"\n",
    "        return re.compile(\"|\".join(map(re.escape, self.keys(  ))))\n",
    "\n",
    "    def __call__(self, match):\n",
    "        \"\"\" Handler invoked for each regex match \"\"\"\n",
    "        return self[match.group(0)]\n",
    "\n",
    "    def clean(self, text):\n",
    "        \"\"\" Substitutes with value for each key and returns the modified text. \"\"\"\n",
    "        return self._make_regex(  ).sub(self, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replacements = {\"\\n\": \" \", # new line characters\n",
    "                \"\\t\": \" \", # tabs\n",
    "                \"-\": \" \",\n",
    "                \"...\": \" \",\n",
    "                \"won't\": \"will not\",\n",
    "                \"can't\": \"can not\",\n",
    "                \"&\": \" and \",\n",
    "                \"\\$*\": \"$\",\n",
    "                \"Loading...\": \" \",\n",
    "                \"Continued...\": \" \",\n",
    "                \"\\N{COPYRIGHT SIGN}\": \" \",\n",
    "                \"\\N{NO-BREAK SPACE}\": \" \",\n",
    "                \"\\N{LEFT-POINTING DOUBLE ANGLE QUOTATION MARK}\": \" \",\n",
    "                \"\\N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}\": \" \",\n",
    "                '.\"': '\".',\n",
    "                '?\"': '\"?',\n",
    "                '!\"': '\"!'\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = {'PERSON': 'person',\n",
    "            'FAC': 'landmark',\n",
    "            'ORG': 'organization',\n",
    "            'GPE': 'place',\n",
    "            'LOC': 'location',\n",
    "            'EVENT': 'event',\n",
    "            'WORK_OF_ART': 'artwork',\n",
    "            'LAW': 'law',\n",
    "            'DATE': 'date',\n",
    "            'TIME': 'time',\n",
    "            'PERCENT': 'percent',\n",
    "            'MONEY': 'money',\n",
    "            'QUANTITY': 'quantity',\n",
    "            'CARDINAL': 'number'\n",
    "}\n",
    "\n",
    "ent_order = {'PERSON': 8,\n",
    "            'FAC': 2,\n",
    "            'ORG': 1,\n",
    "            'GPE': 6,\n",
    "            'LOC': 7,\n",
    "            'EVENT': 3,\n",
    "            'WORK_OF_ART': 5,\n",
    "            'LAW': 4,\n",
    "            'DATE': 9,\n",
    "            'TIME': 10,\n",
    "            'PERCENT': 12,\n",
    "            'MONEY': 11,\n",
    "            'QUANTITY': 13,\n",
    "            'CARDINAL': 14,\n",
    "}\n",
    "\n",
    "drop_ents = ['NORP', 'PRODUCT', 'LANGUAGE','ORDINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess = Cleaner(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(in_doc):\n",
    "    count = 0\n",
    "    out_doc = \"\"\n",
    "    #doc = re.sub(r' *\\n(\\n| )*\\n', '\\\\n', in_doc)\n",
    "    #doc = re.sub(r'\\n([.?!])', '\\\\1', doc)\n",
    "    doc = nlp(in_doc)\n",
    "    if doc._.language['language'] != 'en':\n",
    "        return np.nan\n",
    "    for sent in doc.sents:\n",
    "        text = sent.text\n",
    "        if not re.search('[.?!] *$', text) or ':' in text or re.search(r'(?i)you', text):\n",
    "            continue\n",
    "        out_doc += sent.text + ' '\n",
    "        count += 1\n",
    "    if count < 13:\n",
    "        return count\n",
    "    print(count)\n",
    "    ents = [ent for ent in doc.ents if ent.label_ not in drop_ents]\n",
    "    ents = sorted(ents, key=lambda ent: ent_order[ent.label_])\n",
    "    converted = set([])\n",
    "    for ent in ents:\n",
    "        if (ent.text, ent.label_) in converted:\n",
    "            continue\n",
    "        converted.add((ent.text, ent.label_))\n",
    "        if ent.text[0] == '$':\n",
    "            pattern = r'\\{}\\b'.format(ent.text)\n",
    "        else:\n",
    "            pattern = r'\\b{}\\b'.format(ent.text)\n",
    "        out_doc = re.sub(pattern, entities.get(ent.label_, ent.text), out_doc)\n",
    "    return out_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='You'>"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'(?i)you', 'Your address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_quotes(qq):\n",
    "    num = 0\n",
    "    if qq[-2] in ['.', '?', '!']:\n",
    "        punct = qq[-2]\n",
    "    else:\n",
    "        punct = ''\n",
    "    length = len(qq.split())\n",
    "    if length <= 2:\n",
    "        num = 1\n",
    "    elif length <= 12:\n",
    "        num = 2\n",
    "    elif length <= 25:\n",
    "        num = 3\n",
    "    else:\n",
    "        num = 4\n",
    "    return 'quote ' * num + punct\n",
    "\n",
    "def reformat(article):\n",
    "    text = unidecode(article)\n",
    "    if text.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    text = preprocess.clean(text)\n",
    "    text = re.sub(r'^(.{0,50})\\(\\w+\\)', ' ', text) # delete dateline\n",
    "    text = re.sub(r'\\|.*\\|', ' ', text) # delete category headers, bylines, etc. between pipe symbols\n",
    "    text = re.sub(r'\\S*@\\S+', 'email', text) # replace email address or Twitter handle with \"email\"\n",
    "    text = re.sub(r'[-a-zA-Z0-9@:%_\\+.~#?&\\/=]{2,256}\\.[a-z]{2,4}(\\/[-a-zA-Z0-9@:%_\\+.~#?&\\/=]*)?', ' website',\n",
    "                  text) # URLs\n",
    "    text = re.sub('[\\[\\(][^\\[\\(]*[\\]\\)]', '', text) # delete text inside parentheses or brackets\n",
    "    text = re.sub(r\"\\b(\\w*)n't\", lambda m: m.group(1) + ' not', text) # replace \"xxn't\" contractions with \"xx not\"; \"won't\" already handled\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text\n",
    "    text = re.sub(r\"^'|'$|(?<= )'|(?<!s)'(?= )\", '\"', text) # replace single quotes, but not apostrophes, with double quotes\n",
    "    if text.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text\n",
    "    text = re.sub(r'(?i)please share this.*', '', text)\n",
    "    text = re.sub(' +', ' ', text) # reduce all multiple spaces to single spaces\n",
    "    return process(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "political = pd.read_csv('corpus/political.csv', header=None, names=['id', 'type', 'domain', 'content'], dtype={'id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_articles(df):\n",
    "    for ix, row in df.sample(10).iterrows():\n",
    "        yield helper(ix, row)\n",
    "        \n",
    "def helper(ix, row):\n",
    "    print(ix, ', ', row['domain'])\n",
    "    print(reformat(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['baptistnews.com', 'nationalreview.com', 'dailycaller.com',\n",
       "       'rinf.com', 'washingtonexaminer.com', 'breitbart.com',\n",
       "       'judicialwatch.org', 'guardianlv.com', 'city-journal.org',\n",
       "       'ecowatch.com', 'weeklystandard.com', 'pjmedia.com',\n",
       "       'mintpressnews.com', 'freedomworks.org', 'alternet.org',\n",
       "       'conservativereview.com', 'yellowhammernews.com',\n",
       "       'filmsforaction.org', 'rawstory.com', 'theintercept.com',\n",
       "       'commondreams.org', 'dailykos.com', 'thinkprogress.org',\n",
       "       'thedailybeast.com', 'counterpunch.org', 'observer.com',\n",
       "       'americannewsx.com', 'americanprogress.org', 'ronpaulinstitute.org',\n",
       "       'theblaze.com', 'jacobinmag.com', 'foreignpolicyjournal.com',\n",
       "       'heritage.org', 'countercurrents.org', 'newcoldwar.org',\n",
       "       'nakedcapitalism.com', 'commentarymagazine.com', 'redstate.com',\n",
       "       'counterinformation.wordpress.com', 'oann.com',\n",
       "       'dissentmagazine.org', 'economicnoise.com', 'mrc.org',\n",
       "       'advocate.com', 'ijr.com', 'geopolmonitor.com', 'attn.com',\n",
       "       'drudgereport.com', 'chroniclesmagazine.org',\n",
       "       'jackpineradicals.com', 'thefifthcolumnnews.com', 'fusion.net',\n",
       "       'dennismichaellynch.com', 'proudemocrat.com', 'resistancereport.com'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_contents(df):\n",
    "    for domain in df['domain'].unique():\n",
    "        print(domain)\n",
    "        num = min(len(df[df['domain'] == domain]), 10)\n",
    "        yield df[df['domain'] == domain].sample(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pol_domains = show_contents(political)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-572-288271b4acc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpol_domains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(pol_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Sanctuary cities” throughout the United States have pledged to be a place of refuge and safe harbor for immigrants regardless of their documentation. This stands in stark contrast to a political party that encourages mass deportations and chants ‘Built The Wall’ that controls the mechanisms of government.\\n\\nIn a dramatic move Monday, Attorney General Jeff Sessions said jurisdictions must be able to demonstrate they are not sanctuary cities in order to receive any grants from the Justice Department. Jurisdictions unable to prove a negative could lose out on billions.\\n\\n“This disregard for law must end,” said Sessions.\\n\\nWhile sanctuary cities don’t actively protect undocumented immigrants, they usually have policies that avoid communication with immigration authorities.\\n\\n“LAPD has never participated in programs that deputize local law enforcement to act as immigration agents, and on my watch they never will,” said Los Angeles mayor Eric Garcetti.\\n\\nNew York’s Attorney General Eric Schneiderman vowed to oppose the Trump administration‘s attempt to end sanctuary cities.\\n\\n“My office will continue to ensure local governments have the tools they need to legally protect their immigrant communities – and we won’t stop fighting to beat back President Trump’s un-American immigration policies.”\\n\\nThe financial threats from Sessions are part of a broader-based assault on the concept of sanctuary cities’ home rule on the part of right-wing government.\\n\\nImmigration and Customs Enforcement (ICE) has been increasing enforcement operations in sanctuary cities in an effort to pressure those locations to abandon their policies or to make them less attractive to immigrants, CNN reports.\\n\\nAfter Travis County, Texas chose to limit its involvement with immigration enforcement, ICE launched increased operations and probes in the area. US Magistrate Judge Andrew Austin seemed to confirm this was a direct result of the ‘sanctuary’ policies.\\n\\n“My understanding, what was told to us, is that one of the reasons that happened was because the meetings that had occurred between the [ICE] field office director and the sheriff didn’t go very well,” said Austin. “There was going to be a specific operation, and it was at least related to us in that meeting that it was a result of the sheriff’s new policy that this was going to happen.”\\n\\nICE denies this was the motivation for their operations categorically.\\n\\n“Rumors and reports that recent ICE operations are specifically targeting Travis County, Texas, apart from normal operations, are inaccurate,” read an ICE statement, although it added that “more ICE operational activity is required to conduct at-large arrests in any law enforcement jurisdiction that fails to honor ICE immigration detainers.”\\n\\nThe Department of Homeland Security, which oversees ICE, also recently released a list of suspected sanctuary cities.\\n\\nThat list likely won’t be adding locations from Mississippi, as that state’s governor, Republican Phil Bryant, signed into law a ban on sanctuary cities and other policies that would in any way slow or inhibit ICE operations.\\n\\n“The president said these jurisdictions have caused immeasurable harm to the American people and to the very fabric of the republic,” said Bryant.\\n\\nThe new law overturns the only sanctuary policy in Mississippi, a 2010 ordinance in the city of Jackson that prevented local law enforcement from asking about immigration status.'"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political.loc[793439, 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "political_credible = ['baptistnews.com', 'nationalreview.com', 'mintpressnews.com', 'theintercept.com', 'jacobinmag.com',\n",
    "                     'foreignpolicyjournal.com', 'heritage.org', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "political_biased = ['dailycaller.com', 'breitbart.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "political_bogus = ['dailycaller.com', 'breitbart.com', 'weeklystandard.com', 'pjmedia.com', 'freedomworks.org',\n",
    "                  'alternet.org', 'conservativereview.com', 'commondreams.org', 'dailykos.com', 'thinkprogress.org',\n",
    "                  'counterpunch.org', 'americannewsx.com', 'ronpaulinstitute.org', 'theblaze.com', 'newcoldwar.org',\n",
    "                  'commentarymagazine.com', 'redstate.com', 'economicnoise.com', 'mrc.org', 'ijr.com', 'thefifthcolumnnews.com'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_keepers = ['thecommonsenseshow.com', 'rickwells.us', 'viralliberty.com', 'downtrend.com', 'thelastgreatstand.com',\n",
    "              'yesimright.com', 'usasupreme.com', 'usadailytime.com', 'freedomdaily.com', 'uspoln.com', 'usanewsflash.com',\n",
    "              'onepoliticalplaza.com', 'thefreepatriot.org', 'donaldtrumpnews.co', 'goneleft.com', 'onlineconservativepress.com',\n",
    "              'redrocktribune.com', 'redcountry.us', 'learnprogress.org', 'usadosenews.com', 'usafirstinformation.com',\n",
    "              'enhlive.com', 'flashnewscorner.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake = fake[fake['domain'].isin(fake_keepers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14743"
      ]
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_keepers = ['wnd.com', 'frontpagemag.com', 'americanthinker.com', 'dailywire.com', 'thegatewaypundit.com', \n",
    "               'antiwar.com', 'truthrevolt.org', 'patriotpost.us', 'russia-insider.com', 'paulcraigroberts.org',\n",
    "               'vdare.com', 'off-guardian.org', 'jamesrgrangerjr.com', 'americablog.com', 'americasfreedomfighters.com',\n",
    "               'heartland.org', 'palmerreport.com', 'thefederalistpapers.org', 'conservativetribune.com',\n",
    "               'winningdemocrats.com', '100percentfedup.com', 'cowgernation.com', 'usherald.com', 'darkpolitricks.com',\n",
    "               'newslogue.com', 'usapoliticstoday.com', 'counterjihad.com', 'platosguns.com', 'meanlefthook.com',\n",
    "               'americanpatriotdaily.com', 'endingthefed.com', 'conservativefiringline.com', 'politicalcult.com',\n",
    "               'readconservatives.news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = bias[bias['domain'].isin(bias_keepers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195684"
      ]
     },
     "execution_count": 1133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fake['thebigriddle.com'] = junk sci/consp\n",
    "fake['itaglive.com'] = satire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformat(political.loc[1530054, 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "scraper_data = os.listdir('./data')\n",
    "scraped = pd.DataFrame()\n",
    "for file in scraper_data:\n",
    "    try:\n",
    "        df = pd.read_json('./data/{}'.format(file))\n",
    "        scraped = pd.concat([scraped, df])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped = scraped.drop_duplicates(['id'], keep='last')\n",
    "len(scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.drop('id', axis=1).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.drop('domain', axis=1).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1[(df1['type'] != 'unreliable') & (df1['type'] !='unknown')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1[(df1['type'] != 'unreliable') & (df1['type'] !='unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.groupby('type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[df1['type'] == 'political']['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "media_bias = pd.read_csv('data/media_bias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "media_bias[media_bias['Vertical Rank'] >= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_data = pd.read_json('data/abc_20181207.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_data.loc[13, 'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"https://cbsnews.com/world\".count(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
