{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible = pd.read_csv('corpus/credible.csv', header=None, names=['id', 'type', 'domain', 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible = credible[(credible['domain'] != 'www.msn.com') & (credible['domain'] != 'feed.reuters.com')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "others = credible[~credible['domain'].isin(['nytimes.com', 'nationalreview.com', 'www.reuters.com', 'weeklystandard.com'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "nlp = spacy.load('en')\n",
    "nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cleaner(dict):\n",
    "    \"\"\" Multiple-string-substitution dict \"\"\"\n",
    "    def _make_regex(self):\n",
    "        \"\"\" Build re object based on the keys of the dictionary it is instantiated with\"\"\"\n",
    "        return re.compile(\"|\".join(map(re.escape, self.keys(  ))))\n",
    "\n",
    "    def __call__(self, match):\n",
    "        \"\"\" Handler invoked for each regex match \"\"\"\n",
    "        return self[match.group(0)]\n",
    "\n",
    "    def clean(self, text):\n",
    "        \"\"\" Substitutes with value for each key and returns the modified text. \"\"\"\n",
    "        return self._make_regex(  ).sub(self, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replacements = {#\"\\n\": \" \", # new line characters\n",
    "                \"\\t\": \" \", # tabs\n",
    "                \"-\": \" \",\n",
    "                \"won't\": \"will not\",\n",
    "                \"can't\": \"can not\",\n",
    "                \"&\": \" and \",\n",
    "                \"$$\": \"$\",\n",
    "                \"Loading...\": \" \",\n",
    "                \"Continued...\": \" \",\n",
    "                \"\\N{COPYRIGHT SIGN}\": \" \",\n",
    "                \"\\N{NO-BREAK SPACE}\": \" \",\n",
    "                \"\\N{LEFT-POINTING DOUBLE ANGLE QUOTATION MARK}\": \" \",\n",
    "                \"\\N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}\": \" \",\n",
    "                '.\"': '\".',\n",
    "                '?\"': '\"?',\n",
    "                '!\"': '\"!',\n",
    "                \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = {'PERSON': 'person',\n",
    "            'FAC': 'landmark',\n",
    "            'ORG': 'organization',\n",
    "            'GPE': 'place',\n",
    "            'LOC': 'location',\n",
    "            'EVENT': 'event',\n",
    "            'WORK_OF_ART': 'artwork',\n",
    "            'LAW': 'law',\n",
    "            'DATE': 'date',\n",
    "            'TIME': 'time',\n",
    "            'PERCENT': 'percent',\n",
    "            'MONEY': 'money',\n",
    "            'QUANTITY': 'quantity',\n",
    "            'CARDINAL': 'number'\n",
    "}\n",
    "\n",
    "ent_order = {'PERSON': 8,\n",
    "            'FAC': 2,\n",
    "            'ORG': 1,\n",
    "            'GPE': 6,\n",
    "            'LOC': 7,\n",
    "            'EVENT': 3,\n",
    "            'WORK_OF_ART': 5,\n",
    "            'LAW': 4,\n",
    "            'DATE': 9,\n",
    "            'TIME': 10,\n",
    "            'PERCENT': 12,\n",
    "            'MONEY': 11,\n",
    "            'QUANTITY': 13,\n",
    "            'CARDINAL': 14,\n",
    "}\n",
    "\n",
    "drop_ents = ['NORP', 'PRODUCT', 'LANGUAGE','ORDINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess = Cleaner(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(in_doc):\n",
    "    count = 0\n",
    "    out_doc = \"\"\n",
    "    doc = nlp(in_doc)\n",
    "    if doc._.language['language'] != 'en':\n",
    "        return np.nan\n",
    "    for sent in doc.sents:\n",
    "        ending = sent[-1]\n",
    "        if ending.pos_ != 'PUNCT':\n",
    "            continue\n",
    "        out_doc += (sent.text + ' ')\n",
    "        if ending.text in ['.', '?', '!']:\n",
    "            count += 1\n",
    "    if count < 13:\n",
    "        return count\n",
    "    print(count)\n",
    "    ents = [ent for ent in doc.ents if ent.label_ not in drop_ents]\n",
    "    ents = sorted(ents, key=lambda ent: ent_order[ent.label_])\n",
    "    converted = set([])\n",
    "    for ent in ents:\n",
    "        if (ent.text, ent.label_) in converted:\n",
    "            continue\n",
    "        converted.add((ent.text, ent.label_))\n",
    "        pattern = r'\\b{}\\b'.format(ent.text)\n",
    "        out_doc = re.sub(pattern, entities.get(ent.label_, ent.text), out_doc)\n",
    "    return out_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_quotes(qq):\n",
    "    num = 0\n",
    "    length = len(qq.split())\n",
    "    if length <= 4:\n",
    "        num = 1\n",
    "    elif length <= 12:\n",
    "        num = 2\n",
    "    elif length <= 25:\n",
    "        num = 3\n",
    "    else:\n",
    "        num = 4\n",
    "    return 'quote ' * num + '.'\n",
    "\n",
    "def reformat(article):\n",
    "    text = unidecode(article)\n",
    "    if text.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    text = preprocess.clean(text)\n",
    "    text = re.sub(r'^(.{0,50})\\(\\w+\\)', ' ', text) # delete dateline\n",
    "    text = re.sub(r'\\S*@\\S+', 'email', text) # replace email address or Twitter handle with \"email\"\n",
    "    text = re.sub(r' [-a-zA-Z0-9@:%_\\+.~#?&//=]{2,256}\\.[a-z]{2,4}(\\/[-a-zA-Z0-9@:%_\\+.~#?&//=]*)?', ' website',\n",
    "                  text) # URLs\n",
    "    text = re.sub('[\\[\\(][^\\[\\(]*[\\]\\)]', '', text) # delete text inside parentheses or brackets\n",
    "    text = re.sub(r\"\\b(\\w*)n't\", lambda m: m.group(1) + ' not', text) # replace \"xxn't\" contractions with \"xx not\"; \"won't\" already handled\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text\n",
    "    text = re.sub(r\"^'|'$|(?<= )'|(?<!s)'(?= )\", '\\1\"', text) # replace single quotes, but not apostrophes, with double quotes\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text    \n",
    "    if text.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    text = re.sub(r'(\"[^\"]*\")', lambda m: convert_quotes(m.group(1)), text) # replace quoted text\n",
    "    text = re.sub(r'(?i)please share this.*', '', text)\n",
    "    text = re.sub(' +', ' ', text) # reduce all multiple spaces to single spaces\n",
    "    return process(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('corpus/fake.csv', header=None, names=['id', 'type', 'domain', 'content'], dtype={'id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake[fake['domain'] != 'beforeitsnews.com'] .sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = pd.read_csv('corpus/bias.csv', header=None, names=['id', 'type', 'domain', 'content'], dtype={'id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_articles(df):\n",
    "    for ix, row in df.sample(10).iterrows():\n",
    "        yield helper(ix, row)\n",
    "        \n",
    "def helper(ix, row):\n",
    "    print(ix, ', ', row['domain'])\n",
    "    print(reformat(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = show_articles(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['domain', 'wnd.com', 'lifenews.com', 'dailysignal.com',\n",
       "       'charismanews.com', 'frontpagemag.com', 'americanthinker.com',\n",
       "       'wearechange.org', 'dailywire.com', 'lewrockwell.com',\n",
       "       'thegatewaypundit.com', 'antiwar.com', 'truthrevolt.org',\n",
       "       'patriotpost.us', 'journal-neo.org', 'russia-insider.com',\n",
       "       'unz.com', 'paulcraigroberts.org', 'vdare.com', 'off-guardian.org',\n",
       "       'veteranstoday.com', 'sputniknews.com', 'presstv.com',\n",
       "       'rightwingnews.com', 'jamesrgrangerjr.com', 'pravdareport.com',\n",
       "       'washingtonsblog.com', 'truepundit.com', 'americanlookout.com',\n",
       "       'investmentwatchblog.com', 'aheadoftheherd.com',\n",
       "       'conservativehq.com', 'moonofalabama.org', 'intrepidreport.com',\n",
       "       'americablog.com', 'projectveritas.com',\n",
       "       'americasfreedomfighters.com', 'orientalreview.org',\n",
       "       'thenewamerican.com', 'qpolitical.com', 'katehon.com',\n",
       "       'truthandaction.org', 'gulagbound.com', 'heartland.org',\n",
       "       'oathkeepers.org', 'oftwominds.com', 'conservapedia.com',\n",
       "       'centerforsecuritypolicy.org', 'palmerreport.com', 'endtime.com',\n",
       "       'thefederalistpapers.org', 'conservativetribune.com',\n",
       "       'winningdemocrats.com', 'patriotrising.com', 'pravda.ru',\n",
       "       '100percentfedup.com', 'cowgernation.com', 'usherald.com',\n",
       "       'dailytelegraph.com.au', 'darkpolitricks.com', 'newslogue.com',\n",
       "       'thenewsdoctors.com', 'usapoliticstoday.com', 'counterjihad.com',\n",
       "       'platosguns.com', 'defenddemocracy.press',\n",
       "       'unclesamsmisguidedchildren.com', 'horowitzfreedomcenter.org',\n",
       "       'conservativepapers.com', 'meanlefthook.com',\n",
       "       'americanpatriotdaily.com', 'reagancoalition.com',\n",
       "       '4threvolutionarywar.wordpress.com', 'endingthefed.com',\n",
       "       'westernjournalism.com', 'libertyunyielding.com',\n",
       "       'conservativefiringline.com', 'redflagnews.com',\n",
       "       'patriotupdate.com', 'anotherdayintheempire.com',\n",
       "       'politicalcult.com', 'patriotchronicle.com', 'citizensunited.org',\n",
       "       'truthkings.com', 'redstatewatcher.com', 'uschronicle.com',\n",
       "       'conservativespirit.com', 'elelephantintheroom.blogspot.com',\n",
       "       'federalistpress.com', 'debunkingskeptics.com',\n",
       "       'firearmscoalition.org', 'realtimepolitics.com',\n",
       "       'readconservatives.news', 'rightalert.com', 'openmindmagazine.com',\n",
       "       'dailypoliticsusa.com'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_contents(df):\n",
    "    for domain in df['domain'].unique():\n",
    "        print(domain)\n",
    "        num = min(len(df[df['domain'] == domain]), 10)\n",
    "        yield df[df['domain'] == domain].sample(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_domains = show_contents(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanlefthook.com\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>domain</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114545</th>\n",
       "      <td>722798</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>Ah, Jan Brewer, how we despise you. And now yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108046</th>\n",
       "      <td>7757409</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>395 SHARES Facebook Twitter Reddit Stumbleupon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108284</th>\n",
       "      <td>7758309</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>545 SHARES Facebook Twitter Reddit Stumbleupon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108103</th>\n",
       "      <td>7757708</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>Creationist extraordinaire Ken Ham is at it ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114584</th>\n",
       "      <td>722933</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>274 SHARES Facebook Twitter Reddit Stumbleupon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108133</th>\n",
       "      <td>7757773</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>1k SHARES Facebook Twitter Reddit Stumbleupon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524750</th>\n",
       "      <td>3569071</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>2.5k SHARES Facebook Twitter Reddit Stumbleupo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107947</th>\n",
       "      <td>7757024</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>David Letterman said what we are all feeling a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108055</th>\n",
       "      <td>7757441</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>On September 16, 2016, Terence Crutcher’s SUV ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107954</th>\n",
       "      <td>7757052</td>\n",
       "      <td>bias</td>\n",
       "      <td>meanlefthook.com</td>\n",
       "      <td>The old saying goes like this: Everything's bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  type            domain  \\\n",
       "114545    722798  bias  meanlefthook.com   \n",
       "1108046  7757409  bias  meanlefthook.com   \n",
       "1108284  7758309  bias  meanlefthook.com   \n",
       "1108103  7757708  bias  meanlefthook.com   \n",
       "114584    722933  bias  meanlefthook.com   \n",
       "1108133  7757773  bias  meanlefthook.com   \n",
       "524750   3569071  bias  meanlefthook.com   \n",
       "1107947  7757024  bias  meanlefthook.com   \n",
       "1108055  7757441  bias  meanlefthook.com   \n",
       "1107954  7757052  bias  meanlefthook.com   \n",
       "\n",
       "                                                   content  \n",
       "114545   Ah, Jan Brewer, how we despise you. And now yo...  \n",
       "1108046  395 SHARES Facebook Twitter Reddit Stumbleupon...  \n",
       "1108284  545 SHARES Facebook Twitter Reddit Stumbleupon...  \n",
       "1108103  Creationist extraordinaire Ken Ham is at it ag...  \n",
       "114584   274 SHARES Facebook Twitter Reddit Stumbleupon...  \n",
       "1108133  1k SHARES Facebook Twitter Reddit Stumbleupon ...  \n",
       "524750   2.5k SHARES Facebook Twitter Reddit Stumbleupo...  \n",
       "1107947  David Letterman said what we are all feeling a...  \n",
       "1108055  On September 16, 2016, Terence Crutcher’s SUV ...  \n",
       "1107954  The old saying goes like this: Everything's bi...  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(bias_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creationist extraordinaire Ken Ham is at it again. He claimed that atheists have no business using words like “good” and “bad” and “right” and “wrong” because we don’t believe in God.\\n\\nThis goes back to the old and wrong Christian belief that atheists can’t have morals without God or the Bible. He calls on Christians to judge and call out atheists who use these terms.\\n\\nThe idea that atheists can’t have morals is a complete myth. This seems to be a Christian thing, but many religious people feel this way.\\n\\nThere is no logical connection with this argument. Saying that there is no point in being moral without a God is not really a valid argument for Christianity. This is, basically, saying that we can’t be moral without someone watching over us.\\n\\nKen Ham is probably best known for opening and running the Ark Encounter “museum.” It is, supposedly, a replica of Noah’s Ark. It has all kinds of Creationist exhibits inside that completely smack down scientific fact. They have things like humans riding dinosaurs, even though humans didn’t come along until millions of years after dinosaurs became extinct.\\n\\nRecently, he tried to use his Ark Encounter to display a giant middle finger to the LGBT community…by lighting it up with rainbow lights. Yep, he tried to “take back the rainbow” with rainbow lights. Christians have this strange idea that the LGBT community has stolen the rainbow from them. This idiot just needs to go away. Period.\\n\\nFeatured image via Twitter.'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.loc[1108103, 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_keepers = ['wnd.com', 'frontpagemag.com', 'americanthinker.com', 'dailywire.com', 'thegatewaypundit.com', \n",
    "               'antiwar.com', 'truthrevolt.org', 'patriotpost.us', 'russia-insider.com', 'paulcraigroberts.org',\n",
    "               'vdare.com', 'off-guardian.org', 'jamesrgrangerjr.com', 'americablog.com', 'americasfreedomfighters.com',\n",
    "               'heartland.org', 'palmerreport.com', 'thefederalistpapers.org', 'conservativetribune.com',\n",
    "               'winningdemocrats.com', '100percentfedup.com', 'cowgernation.com', 'usherald.com', 'darkpolitricks.com',\n",
    "               'newslogue.com', 'usapoliticstoday.com', 'counterjihad.com', 'platosguns.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Creationist extraordinaire person is at it again. This goes back to the old and wrong Christian belief that atheists can not have morals without person or the artwork. The idea that atheists can not have morals is a complete myth. There is no logical connection with this argument. Saying that there is no point in being moral without a person is not really a valid argument for organization. person is probably best known for opening and running the organization quote .. It has all kinds of Creationist exhibits inside that completely smack down scientific fact. Recently, he tried to use his organization to display a giant middle finger to the organization website lighting it up with rainbow lights. Yep, he tried to quote . with rainbow lights. Christians have this strange idea that the organization community has stolen the rainbow from them. This idiot just needs to go away. person image via person. '"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformat(bias.loc[1108103, 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " | DATE\n",
      "\n",
      "\n",
      "Germany | PERSON\n",
      "Berlin | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "Turkish | NORP\n",
      "Soner Polat | PERSON\n",
      "Sputnik | PERSON\n",
      "Earlier this week | DATE\n",
      "Turkish | NORP\n",
      "Peter Steudtner | PERSON\n",
      "German | NORP\n",
      "six | CARDINAL\n",
      "Amnesty International’s | ORG\n",
      "Turkey | GPE\n",
      "Idil Eser | PERSON\n",
      "Turkish | NORP\n",
      "July 5 | DATE\n",
      "German | NORP\n",
      "Sigmar Gabriel | PERSON\n",
      "Berlin | GPE\n",
      "Ankara | GPE\n",
      "Turkey | GPE\n",
      "Germany | GPE\n",
      "Turkey Spiral | ORG\n",
      "Crisis https://t.co/qDS58JclNa — Janet Orendorff | FAC\n",
      "July 22, 2017 | DATE\n",
      "Turkish | NORP\n",
      "thousands | CARDINAL\n",
      "July 15, 2016 | DATE\n",
      "Islamic | NORP\n",
      "Fethullah Gulen | PERSON\n",
      "Ankara | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "MFA | ORG\n",
      "— Srbija Evropa | PERSON\n",
      "July 20, 2017\n",
      "\n",
      " | DATE\n",
      "Sputnik Turkey | PERSON\n",
      "Retired Rear Admiral | PERSON\n",
      "the Turkish Armed Forces Soner Polat | ORG\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "Turkey | GPE\n",
      "Eurasia | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "1952 | DATE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "NATO | ORG\n",
      "Polat | PERSON\n",
      "Turkey | GPE\n",
      "Turkey | GPE\n",
      "July 15 last year | DATE\n",
      "Turkey | GPE\n",
      "Australia | GPE\n",
      "New Zealand | GPE\n",
      "Europe | LOC\n",
      "the United States | GPE\n",
      "the Justice and Development Party | ORG\n",
      "Turkish | NORP\n",
      "Recep Tayyip Erdogan | PERSON\n",
      "Turkey | GPE\n",
      "Erdogan | PERSON\n",
      "Germany | GPE\n",
      "Injirlik | LOC\n",
      "German | NORP\n",
      "Injirlik | LOC\n",
      "Konya | GPE\n",
      "Polat | PERSON\n",
      "Erdogan | PERSON\n",
      "Europe | LOC\n",
      "Netherlands | GPE\n",
      "Germany | GPE\n",
      "British | NORP\n",
      "Boris Johnson | PERSON\n",
      "Brexit | ORG\n",
      "Turkey | GPE\n",
      "Preventing Erdogan | PERSON\n",
      "the G20 summit | EVENT\n",
      "Turkey | GPE\n",
      "West | LOC\n",
      "Polat | LOC\n",
      "Germany | GPE\n",
      "Eurasian | NORP\n",
      "Turkey | GPE\n",
      "Polat | PERSON\n",
      "Berlin | GPE\n",
      "Ankara | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "German | NORP\n",
      "Turkey | GPE\n",
      "Turkey | GPE\n",
      "Greece | GPE\n",
      "Iraq | GPE\n",
      "Syria | GPE\n",
      "late May | DATE\n",
      "Turkish | NORP\n",
      "Mevlut Cavusoglu | PERSON\n",
      "Ankara | GPE\n",
      "German | NORP\n",
      "Incirlik | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "Incirlik’ | GPE\n",
      "Germany | GPE\n",
      "Turkey | GPE\n",
      "German | NORP\n",
      "Incirlik | GPE\n",
      "Cavusoglu | ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in nlp(bias.loc[265413, 'content']).ents:\n",
    "    print(ent.text, '|', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Hillary', 'person'), ('NAACP', 'org'), ('Whitman', 'bridge')}"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = set([('Hillary', 'person'), ('NAACP', 'org'), ('Whitman', 'bridge'), ('Hillary', 'person')])\n",
    "tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def silliness(string):\n",
    "    new_string = re.sub(r\"^'|'$|(?<= )'|'(?= )\", '\"', string)\n",
    "    print(new_string.count('\\N{QUOTATION MARK}'))\n",
    "    if new_string.count('\\N{QUOTATION MARK}') % 2 != 0:\n",
    "        return np.nan\n",
    "    return 'WTF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester = nlp('Victims seek to resume Marcos from Heroes\\' Cemetery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tester:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial = 'How about \\u00a9 for a change'\n",
    "print(trial)\n",
    "trial2 = re.sub('\\N{COPYRIGHT SIGN}', 'this', trial)\n",
    "print(trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'How about \\u00a9 for a change'.replace('\\N{COPYRIGHT SIGN}', 'this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "scraper_data = os.listdir('./data')\n",
    "scraped = pd.DataFrame()\n",
    "for file in scraper_data:\n",
    "    try:\n",
    "        df = pd.read_json('./data/{}'.format(file))\n",
    "        scraped = pd.concat([scraped, df])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped = scraped.drop_duplicates(['id'], keep='last')\n",
    "len(scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.drop('id', axis=1).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1.drop('domain', axis=1).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df1[(df1['type'] != 'unreliable') & (df1['type'] !='unknown')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1[(df1['type'] != 'unreliable') & (df1['type'] !='unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.groupby('type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[df1['type'] == 'political']['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "media_bias = pd.read_csv('data/media_bias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "media_bias[media_bias['Vertical Rank'] >= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_data = pd.read_json('data/abc_20181207.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_data.loc[13, 'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"https://cbsnews.com/world\".count(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
