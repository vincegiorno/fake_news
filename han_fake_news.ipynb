{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Embedding, GRU, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cleaned/cred_sample', 'rb') as infile:\n",
    "    cred = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cleaned/hate', 'rb') as infile:\n",
    "    hate = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate) > len(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hate = hate.sample(len(cred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate) == len(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hate['label'] = 0\n",
    "cred['label'] = 1\n",
    "data = cred.append(hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>domain</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411362</th>\n",
       "      <td>8147326</td>\n",
       "      <td>reliable</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>Email A former college basketball star and org...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418499</th>\n",
       "      <td>8166066</td>\n",
       "      <td>reliable</td>\n",
       "      <td>www.theguardian.com</td>\n",
       "      <td>T he organization supporting press has mounted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461099</th>\n",
       "      <td>8280513</td>\n",
       "      <td>reliable</td>\n",
       "      <td>www.nytimes.com</td>\n",
       "      <td>whose software helps police departments organi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419932</th>\n",
       "      <td>8170120</td>\n",
       "      <td>reliable</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>Email She was the secret power behind the Sout...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369785</th>\n",
       "      <td>8026492</td>\n",
       "      <td>reliable</td>\n",
       "      <td>www.politico.com</td>\n",
       "      <td>Share on Facebook Share on Twitter A typical b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id      type               domain  \\\n",
       "411362  8147326  reliable       abcnews.go.com   \n",
       "418499  8166066  reliable  www.theguardian.com   \n",
       "461099  8280513  reliable      www.nytimes.com   \n",
       "419932  8170120  reliable       abcnews.go.com   \n",
       "369785  8026492  reliable     www.politico.com   \n",
       "\n",
       "                                                  content  label  \n",
       "411362  Email A former college basketball star and org...      1  \n",
       "418499  T he organization supporting press has mounted...      1  \n",
       "461099  whose software helps police departments organi...      1  \n",
       "419932  Email She was the secret power behind the Sout...      1  \n",
       "369785  Share on Facebook Share on Twitter A typical b...      1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 100\n",
    "max_sentences = 15\n",
    "max_vocab = 50000\n",
    "embedding_dim = 100\n",
    "attention_dim = 128\n",
    "test_val_size = 0.2\n",
    "articles = []\n",
    "texts = []\n",
    "embeddings = {}\n",
    "\n",
    "vector_dir = './embeddings'\n",
    "vector_file = 'glove.6B.100d.txt'\n",
    "model_dir = './model_output/glove_100'\n",
    "tb_logs = './tb_logs/glove_100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HierarchicalAttentionNetwork(Layer):\n",
    "    ''''''\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init_weights = initializers.get('glorot_normal')\n",
    "        self.init_bias = initializers.get('zeros')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(HierarchicalAttentionNetwork, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init_weights((input_shape[-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init_bias((self.attention_dim,)))\n",
    "        self.u = K.variable(self.init_weights((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(HierarchicalAttentionNetwork, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x: [batch_size, max_words/max_sentences, attention_dim]\n",
    "        # size of u: [batch_size, attention_dim]\n",
    "        # uit = tanh(Wx + b)\n",
    "        # ait = softmax(uit*u)\n",
    "        \n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "\n",
    "        ait = K.exp(K.squeeze(K.dot(uit, self.u), -1))\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        \n",
    "        weighted_input = x * K.expand_dims(ait)\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['content'], data['label'], test_size=test_val_size,\n",
    "                                                    random_state=19, stratify=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "for text in data['content']:\n",
    "    texts.append(text)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80473"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(filepath=model_dir+'weights.{epoch:02d}.hdf5')\n",
    "tb_checkpoint = TensorBoard(log_dir=tb_logs, histogram_freq=1, batch_size=128, write_graph=False, write_grads=True,\n",
    "                            write_images=True)\n",
    "\n",
    "# callbacks=[model_checkpoint, tb_checkpoint]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
